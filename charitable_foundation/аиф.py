# -*- coding: utf-8 -*-
"""АИФ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zhuzr0LSNE0GaLJjCFQLR-rKRFvqoXfH

<h1> Благотворительный фонд «АИФ» <h1/>

Нам предоставлены для анализа данные благотворительного фонда. Проведем анализ пользователей, чтобы отследить паттерны в поведении и выявить закономерности, которые могут способствовать более успешному продвижению платформы.

### Загрузка данных
"""

# Commented out IPython magic to ensure Python compatibility.
import chardet
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import plotly.express as px
from datetime import datetime, timedelta
from statsmodels.stats.proportion import proportions_ztest
import requests
import zipfile
import io
import pickle
import os
import datetime as dt
from scipy import stats
from pandas.plotting import register_matplotlib_converters
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Скачивание файлов
!gdown --id 12cwP3UbMbmfHKXlAUMyy2AwDrSq7N_Dxste--nXKbZo
!gdown --id 1hVpltdEeZzpJdy5qbzsJIu71esfOZbyKzlbY4bUyITE
!gdown --id 1ar70rR009ssh834xWWBckp_D0sHbFZ5Z2dsoWKIF1is

# Анализ кодировок
files = ['id_donor.xlsx', 'import_p.xlsx', 'order.xlsx']
for file in files:
    with open(file, 'rb') as f:
        encoding = chardet.detect(f.read())['encoding']
    print(f"Кодировка файла {file}: {encoding}")

# Чтение файлов
id_donor = pd.read_excel('id_donor.xlsx')
customer_action = pd.read_excel('import_p.xlsx')
order = pd.read_excel('order.xlsx')

pd.options.display.max_colwidth = 100

file_id = '1gmrJA1c0A6Kz4zPP5keOdaSk6Xq8uN5Z'
url = f'https://drive.google.com/uc?id={file_id}'

response = requests.get(url)
if response.status_code == 200:
    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:
        zip_ref.extractall('unzipped_folder')
        print("Zip file extracted successfully.")
else:
    print("Failed to download the file.")

# Путь к распакованной папке
folder_path = 'unzipped_folder'

# Проверяем, существует ли папка
if os.path.exists(folder_path):
    # Получаем список файлов в папке
    files = os.listdir(folder_path)
    if files:
        for file in files:
            file_link = f'<a href="{folder_path}/{file}" target="_blank">{file}</a>'
            print(f"Имя файла: {file}, Ссылка: {file_link}")
    else:
        print("Папка пуста.")
else:
    print("Папка не существует.")

# Получаем список файлов в текущей директории (распакованной папке)
files = os.listdir('unzipped_folder/part_2')

# Проходим по каждому файлу и выводим его имя и ссылку
for file in files:
    # Проверяем, что файл является файлом, а не директорией
    if os.path.isfile(os.path.join('unzipped_folder/part_2', file)):
        # Формируем ссылку на файл
        file_link = f'<a href="./unzipped_folder/part_2/{file}" target="_blank">{file}</a>'
        print(f"Имя файла: {file}, Ссылка: {file_link}")

with open('./unzipped_folder/part_2/channels.pkl', 'rb') as f:
    channels = pickle.load(f)

"""### Предварительная обработка данных"""

# Стили для графиков
sns.set_palette('husl')
plt.set_cmap('viridis')
plt.style.use('seaborn')

# Удаление полностью пустых столбцов
customer_action = customer_action.dropna(axis=1, how='all')
id_donor = id_donor.dropna(axis=1, how='all')
order = order.dropna(axis=1, how='all')
channels = channels.dropna(axis=1, how='all')

'''channels.sort_values(by=['user_id', 'action_date'])'''

channels = channels.iloc[:873421]
channels.reset_index(drop=True, inplace=True)

display(customer_action.duplicated().sum())
display(id_donor.duplicated().sum())
display(order.duplicated().sum())
display(channels.duplicated().sum())

channels = channels.drop_duplicates()
print(f'Всего {channels.duplicated().sum()} дубликатов.')

customer_action.columns = [x.lower().replace('customeraction', '') for x in customer_action.columns.values]
order.columns = [x.lower().replace('order', '') for x in order.columns.values]
id_donor.columns = [x.lower().replace('customer', '') for x in id_donor.columns.values]

# Проверка идентичности двух столбцов
are_equal = customer_action['datetimeutc'] == customer_action['creationdatetimeutc']
print(are_equal.nunique())

# Удаление столбца по имени
customer_action.drop(columns=['creationdatetimeutc'], inplace=True)

channels.info()

customer_action.info()

id_donor.info()

# Заменяем пробелы и всё, что идет после пробела на пустую строку
id_donor.rename(columns=lambda x: x.split(' = ')[0].strip(), inplace=True)
order.rename(columns=lambda x: x.split(' = ')[0].strip(), inplace=True)

print("DataFrame 'order':")
'''display(order.isnull().sum())
display(order.head(3))
print(order['customfieldsrecurrent'].value_counts())'''

order.info()

print("DataFrame 'id_donor':")
'''display(id_donor.isnull().sum())
display(id_donor.head(3))'''

print("DataFrame 'import':")
'''display(customer_action.isnull().sum())
display(customer_action.head(3))'''

# Заполнение пропусков в общих подписках
id_donor['subscriptionsdobroaifissubscribed'] = id_donor[
    ['subscriptionsdobroaifsmsissubscribed','subscriptionsdobroaifemailissubscribed',
     'subscriptionsdobroaifviberissubscribed','subscriptionsdobroaifmobilepushissubscribed',
     'subscriptionsdobroaifwebpushissubscribed']].any(axis=1)


# Заполнение пропусков модой с учетом среза данных
for col in ['ianatimezone']:
    # Вычисление моды внутри среза данных для каждого столбца
    # Выбираем строки и столбцы с индексами
    cut_conditions = id_donor.iloc[:23820, [3, 4]]
    mode_value = id_donor.loc[cut_conditions.index, col].mode().iloc[0]
    # Заполнение пропусков в соответствии с модой среза данных
    id_donor[col].fillna(mode_value, inplace=True)

for col in ['areaname']:
    cut_conditions = id_donor.iloc[:23820, [3, 5]]
    mode_value = id_donor.loc[cut_conditions.index, col].mode().iloc[0]
    id_donor[col].fillna(mode_value, inplace=True)

for col in ['areaidsexternalid']:
    cut_conditions = id_donor.iloc[:23820, [4, 5]]
    mode_value = id_donor.loc[cut_conditions.index, col].mode().iloc[0]
    id_donor[col].fillna(mode_value, inplace=True)

'''display(channels['utm_medium'].unique())'''

for col in ['utm_source']:
    cut_conditions = channels.iloc[:2640001, [2, 4]]
    mode_value = channels.loc[cut_conditions.index, col].mode().iloc[0]
    channels[col].fillna(mode_value, inplace=True)

'''display(channels.isnull().sum())'''

# Проверка наличия одинаковых идентификаторов в двух разных DataFrame

are_equal = order['customeridsmindboxid'].isin(id_donor['idsmindboxid'])
print(are_equal.any())

# Обработка аномальных значений. Преобразование отрицательных значений в положительные
order[['totalprice', 'linebasepriceperitem',
          'linequantity', 'linepriceofline']] = order[['totalprice',
           'linebasepriceperitem', 'linequantity', 'linepriceofline']].apply(abs)

# Создание булевого условия для строк, где значения `повторный рекуррент` и `регулярный да/нет` отсутствуют
condition = (order['customeridsmindboxid'].duplicated(keep=False)) & (order['customfieldsrepayment'].isnull())

# Заполнение пропущенных значений в соответствии с булевым условием
order.loc[condition, 'customfieldsrepayment'] = True

# Заполнение цены продукта за единицу
for col in ['linebasepriceperitem']:
    cut_conditions = order.iloc[:73763, [11,12]]
    mode_value = order.loc[cut_conditions.index, col].mode().iloc[0]
    order[col].fillna(mode_value, inplace=True)

# Заполнение наименований продукта
for col in ['lineproductname']:
    cut_conditions = order.iloc[:73763, [11,14]]
    mode_value = order.loc[cut_conditions.index, col].mode().iloc[0]
    order[col].fillna(mode_value, inplace=True)

# Проверка идентичности двух столбцов

are_equal = order['firstactionchannelidsexternalid'] == order['firstactionchannelname']
print(are_equal.nunique())

# Удаление столбца по имени
order.drop(columns=['firstactionchannelidsexternalid'], inplace=True)

# Заполнение отсутствующих значений пустой строкой

id_donor.fillna('', inplace=True)
order.fillna('', inplace=True)
channels.fillna('', inplace=True)

# +3 часа к столбцам changedatetimeutc и firstactiondatetimeutc

id_donor.changedatetimeutc = id_donor.changedatetimeutc + pd.Timedelta('3h')
order.firstactiondatetimeutc = order.firstactiondatetimeutc + pd.Timedelta('3h')

# Разделение времени в соответствии с сутками

id_donor['changedatetimeutc'] = pd.to_datetime(id_donor['changedatetimeutc'])
channels['action_date'] = pd.to_datetime(channels['action_date'])
order['firstactiondatetimeutc'] = pd.to_datetime(order['firstactiondatetimeutc'])

def get_time_of_day(timestamp):
    hour = timestamp.hour
    if 6 <= hour < 12:
        return 'morning'
    elif 12 <= hour < 18:
        return 'day'
    else:
        return 'night'

id_donor['time_of_day'] = id_donor['changedatetimeutc'].apply(get_time_of_day)
order['time_of_day'] = order['firstactiondatetimeutc'].apply(get_time_of_day)

# Разделение дат по дням

id_donor['day_of_week'] = id_donor['changedatetimeutc'].dt.dayofweek.map(
    {0: 'пн', 1: 'вт', 2: 'ср', 3: 'чт', 4: 'пт', 5: 'сб', 6: 'вс'})
order['day_of_week'] = order['firstactiondatetimeutc'].dt.dayofweek.map(
    {0: 'пн', 1: 'вт', 2: 'ср', 3: 'чт', 4: 'пт', 5: 'сб', 6: 'вс'})

# Переименование столбцов

order.rename(columns={'customeridsmindboxid': 'user_id'}, inplace=True)
id_donor.rename(columns={'idsmindboxid': 'user_id'}, inplace=True)

# Вычисление разницы во времени между последовательными значениями в столбцах с датами
# для каждого пользователя

id_donor['time_diff'] = id_donor.groupby('user_id')['changedatetimeutc'].diff()
order['time_diff'] = order.groupby('user_id')['firstactiondatetimeutc'].diff()

# Создание session_id для каждой сессии пользователя на основе временной разницы больше 30 минут

id_donor['session_id'] = id_donor.groupby(['user_id', (id_donor['time_diff'] > pd.Timedelta(
    '30Min')).cumsum()]).ngroup() + 1
order['session_id'] = order.groupby(['user_id', (order['time_diff'] > pd.Timedelta(
    '30Min')).cumsum()]).ngroup() + 1

# Объединение данные из разных таблиц по столбцу 'user_id'

id_donor_order = id_donor.merge(order, on='user_id', how='left')
id_donor_channel = id_donor.merge(channels, on='user_id', how='left')
channel_order = channels.merge(order, on='user_id', how='left')

"""### Исследовательский анализ"""

print(f'Дата начала в donor: {id_donor["changedatetimeutc"].min()}')
print(f'Дата окончания в donor: {id_donor["changedatetimeutc"].max()}')

print(f'Дата начала в import: {customer_action["datetimeutc"].min()}')
print(f'Дата окончания в import: {customer_action["datetimeutc"].max()}')

print(f'Дата начала в order: {order["firstactiondatetimeutc"].min()}')
print(f'Дата окончания в order: {order["firstactiondatetimeutc"].max()}')

print(f'Дата начала в channels: {channels["action_date"].min()}')
print(f'Дата окончания в channels: {channels["action_date"].max()}')

"""Данные регистрация предоставлены с 2022 года, а данные по оплате заказов — с 2021. Информация по каналам доступна на год раньше, чем сведения об оплате."""

fig = px.histogram(order,
                   x='totalprice',
                   color='lineproductname',
                   range_x=[0, 8000],
                   title='Распределение средств. Стоимость заказа',
                   nbins=1000,
                   barmode='overlay')
fig.update_xaxes(title_text='Значение')
fig.update_yaxes(title_text='Частота')
fig.update_layout(
    legend=dict(
    title='Продукт'))
fig.show()

"""Основная часть средств была использована для поддержания и развития основной деятельности организации."""

# Расчет среднего чека (AOV)
AOV = order['totalprice'].sum() / order['firstactiondatetimeutc'].nunique()

# Расчет среднего количества заказов
avg_orders = order.groupby('user_id')['firstactiondatetimeutc'].nunique().mean()

print(f"AOV платящих пользователей: {AOV}")
print(f"Среднее количество заказов платящих пользователей: {avg_orders}")

# Динамика заказов пользователей по неделям:

order['order_week'] = order['firstactiondatetimeutc'].dt.to_period('W')
order_counts = order.groupby('order_week')['firstactiondatetimeutc'].count()

plt.figure(figsize=(10, 6))
plt.plot(order_counts.index.to_timestamp(), order_counts.values)
plt.xlabel('Неделя')
plt.ylabel('Количество заказов')
plt.title('Динамика заказов пользователей по неделям')
plt.show()

# Динамика изменений прибыли:

weekly_price = order.resample('W', on='firstactiondatetimeutc')['totalprice'].sum()
monthly_revenue = order.resample('M', on='firstactiondatetimeutc')['totalprice'].sum()

fig, ax = plt.subplots(2, 1, figsize=(10, 6))
ax[0].plot(weekly_price.index, weekly_price.values, label='Weekly Revenue')
ax[0].set_title('Динамика изменения дохода по неделям')
ax[0].set_xlabel('Неделя')
ax[0].set_ylabel('Прибыль')
ax[0].legend()

ax[1].plot(monthly_revenue.index, monthly_revenue.values, label='Monthly Revenue')
ax[1].set_title('Динамика изменения дохода по месяцам')
ax[1].set_xlabel('Месяц')
ax[1].set_ylabel('Прибыль')
ax[1].legend()
plt.tight_layout()
plt.show()

"""Наибольшие взносы фонд получает в праздничные дни.

В столбце «Новый год» указано, были ли пожертвования за месяц до указанной даты.
"""

# Группировка данных и вывод статистики

stats_newyear = order.groupby('customfieldsnewyear')['firstactiondatetimeutc'].describe()
stats_newyear

"""### Функции для анализа"""

# Создание профилей

def get_profiles(id_donor, order, channels):

    profiles = (id_donor.sort_values(by=['user_id', 'changedatetimeutc'])
                        .groupby('user_id')
                        .agg({
                            'changedatetimeutc': 'first',
                            'areaname': 'first',
                            'sex': 'first',
                            'session_id': 'first',
                            'subscriptionsdobroaifissubscribed': 'first'
                        })
                        .rename(columns={'changedatetimeutc': 'first_ts'})
                        .reset_index())

    profiles['dt'] = profiles['first_ts'].dt.date
    profiles['dt'] = pd.to_datetime(profiles['dt'])

    def paid(linestatusidsexternalid):
      return linestatusidsexternalid == 'Paid'

    profiles['payer'] = order['linestatusidsexternalid'].apply(paid)
    profiles['totalprice'] = order.groupby('user_id')['totalprice'].sum()

    paid_count = order.groupby('user_id').size().reset_index(name='paid_count')
    profiles = profiles.merge(paid_count, on='user_id', how='left').merge(
        channels, on='user_id', how='left')

    return profiles

profiles = get_profiles(id_donor, order, channels)

profiles.pivot_table(
    index='dt',
    columns='sex',
    values='user_id',
    aggfunc='nunique'
).plot(figsize=(10, 5), grid=True)
plt.show()

"""В июне и июле 2022 года увеличился рост числа новых пользователей. Также в марте 2023 года появилось много новых участников, без информации об их поле. Возможно, это связано с проведением мероприятий, которые привлекли новых волонтёров."""

pivot_table = channels.pivot_table(index='action_date',
    columns='utm_source',values='user_id',aggfunc='nunique')

# Сбросить индекс для использования в Plotly Express
pivot_table = pivot_table.reset_index()

# Преобразование сводной таблицы в длинный формат для Plotly Express
melted_table = pivot_table.melt(id_vars='action_date', var_name='utm_source',
                                value_name='unique_users')

# График данных с помощью Plotly Express
fig = px.line(melted_table, x='action_date', y='unique_users', color='utm_source',
              title='Количество уникальных пользователей на канале с течением времени')
fig.show()

"""После размещения рекламы на других площадках количество уникальных пользователей на основном канале увеличилось."""

pivot_table = channels.pivot_table(index='action_date',
    columns='user_action',values='user_id',aggfunc='nunique')

pivot_table = pivot_table.reset_index()
melted_table = pivot_table.melt(id_vars='action_date', var_name='user_action',
                                value_name='unique_users')

fig = px.line(melted_table,x='action_date',y='unique_users',
    color='user_action',title='Количество уникальных пользователей по событиям с течением времени')

fig.show()

"""Основные изменения в стратегии привлечения клиентов были внедрены с апреля 2022. События с наибольшим количеством задействованных пользователей — это счастливые истории, отправка новостей и отчетности."""

# Когортный анализ

def get_retention(profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=[], ignore_horizon=False):
    profiles['month'] = pd.to_datetime(profiles['first_ts']).dt.to_period('M').dt.start_time
    dimensions = ['payer'] + dimensions
    last_suitable_acquisition_date = observation_date if ignore_horizon else observation_date - timedelta(days=horizon_days - 1)

    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')

    result_raw = profiles.merge(order[['user_id', 'firstactiondatetimeutc']], on='user_id', how='left')
    result_raw['lifetime'] = (result_raw['firstactiondatetimeutc']-result_raw['first_ts']).dt.days

    def group_by_dimensions(df, dims, horizon_days):
        result = df.pivot_table(index=dims, columns='lifetime', values='firstactiondatetimeutc', aggfunc='nunique')
        cohort_sizes = df.groupby(dims).agg({'firstactiondatetimeutc': 'nunique'}).rename(
            columns={'firstactiondatetimeutc': 'cohort_size'})
        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)
        result = result.div(result['cohort_size'], axis=0)
        all_columns = ['cohort_size'] + list(range(horizon_days))
        result = result.reindex(columns=all_columns, fill_value=0)
        result['cohort_size'] = cohort_sizes
        return result

    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)
    result_in_time = group_by_dimensions(result_raw, dimensions + ['dt'], horizon_days)

    return result_raw, result_grouped, result_in_time

"""Проведем анализ, начиная с дат, когда были внедрены изменения, для оценки успешности рекламных компаний."""

# Данные выборочных наблюдений и дни горизонта

observation_date = datetime(2022, 4, 1).date()
horizon_days = 14

retention_raw, retention, retention_history = get_retention(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=['sex'])

display(profiles.sort_values(by='totalprice', ascending=False))

"""У некоторых пользователей срок использования продукта отрицательный из-за разницы в год между датой регистрации и датой оплаты в данных.

Большинство пользователей — это женщины, они составляют почти половину от общего числа.

Пользователи, которые сделали самые крупные пожертвования и имеют подписку, совершили максимум три покупки. Они начали сотрудничать с фондом в 2023 году.
"""

# Функция конверсии

def get_conversion(profiles, id_donor, order, channels, observation_date,
                   horizon_days, dimensions=[], ignore_horizon=False):

    last_suitable_acquisition_date = observation_date
    if not ignore_horizon:
        last_suitable_acquisition_date = observation_date - timedelta(
            days=horizon_days - 1
        )
    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')

    result_raw = profiles.merge(order[['user_id', 'firstactiondatetimeutc']], on='user_id', how='left')
    result_raw['lifetime'] = (result_raw['firstactiondatetimeutc']-result_raw['first_ts']).dt.days

    if len(dimensions) == 0:
        result_raw['cohort'] = 'All users'
        dimensions = dimensions + ['cohort']


    def group_by_dimensions(df, dims, horizon_days):
        result = df.pivot_table(
            index=dims, columns='lifetime', values='user_id', aggfunc='nunique')

        result = result.fillna(0).cumsum(axis = 1)
        cohort_sizes = (
            df.groupby(dims)
            .agg({'user_id': 'nunique'})
            .rename(columns={'user_id': 'cohort_size'})
        )
        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)

        result = result.div(result['cohort_size'], axis=0)
        result = result[['cohort_size'] + list(range(horizon_days))]
        result['cohort_size'] = cohort_sizes
        return result


    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)

    if 'cohort' in dimensions:
        dimensions = []

    result_in_time = group_by_dimensions(
        result_raw, dimensions + ['dt'], horizon_days)

    return result_raw, result_grouped, result_in_time

# Кривые удержания

retention_raw, retention, retention_history = get_retention(
    profiles, id_donor, order, channels, datetime(2022, 4, 1).date(), 14,
    dimensions=['sex'])

plt.figure(figsize=(20, 8))

report = retention_history.drop(columns=['cohort_size', 0])

num_rows = len(profiles['payer'].unique())
num_cols = len(profiles['sex'].unique())

for i, payer in enumerate(profiles['payer'].unique()):
    for j, sex in enumerate(profiles['sex'].unique()):
        (
            report.query('payer == @payer and sex == @sex')
            .droplevel(['payer', 'sex'])
            .plot(
                grid=True,
                ax=plt.subplot(num_rows, num_cols, i * num_cols + j + 1),
            )
        )
        plt.xlabel('Дата привлечения')
        plt.title('Удержание для оплативших = {} на {}'.format(payer, sex))
plt.tight_layout()

plt.figure(figsize=(20, 6))

report = retention.drop(columns=['cohort_size', 0])

for i, payer in enumerate(profiles['payer'].unique()):
    report.query('payer == @payer').droplevel('payer').T.plot(
        grid=True,
        xticks=list(report.columns.values),
        ax=plt.subplot(1, 2, i + 1),
    )
    plt.xlabel('Лайфтайм')
    plt.title('Кривые удержания по оплатившим = {}'.format(payer))

plt.show()

"""Показатели удержания нестабильны для всех пользователей. Лучше всего удаётся удерживать клиентов c указанным генднром, которые уже совершали оплату."""

# Функция для визуализации удержания

def plot_retention(retention, retention_history, horizon, window=7):

    # Удаление ненужных столбцов
    retention = retention.drop(columns=['cohort_size', 0])
    retention_history = retention_history.drop(columns=['cohort_size'])[[horizon - 1]]

    if retention.index.nlevels == 1:
        retention['cohort'] = 'All users'
        retention = retention.reset_index().set_index(['cohort', 'payer'])

    fig = make_subplots(rows=2, cols=2, subplot_titles=('Удержание платящих пользователей',
                                                        'Удержание неплатящих пользователей'))

    retention_paying = retention.query('payer == True').droplevel('payer').T
    for cohort in retention_paying.columns:
        fig.add_trace(
            go.Scatter(x=retention_paying.index, y=retention_paying[cohort], mode='lines', name=cohort),
            row=1, col=1
        )

    retention_non_paying = retention.query('payer == False').droplevel('payer').T
    for cohort in retention_non_paying.columns:
        fig.add_trace(
            go.Scatter(x=retention_non_paying.index, y=retention_non_paying[cohort], mode='lines',
                       name=cohort), row=1, col=2)

    fig.update_xaxes(title_text='Лайфтайм', row=1, col=1)
    fig.update_xaxes(title_text='Лайфтайм', row=1, col=2)

    fig.update_layout(title='Удержание', height=800, width=1200,
                      showlegend=False)
    fig.show()

# Функция для визуализации конверсии

def plot_conversion(conversion, conversion_history, horizon, window=7):

    conversion = conversion.drop(columns=['cohort_size'])
    conversion_history = conversion_history.drop(columns=['cohort_size'])[[horizon - 1]]

    fig = make_subplots(rows=1, cols=2, subplot_titles=(
        'Конверсия пользователей', f'Динамика конверсии пользователей на {horizon}-й день'))

    # Коэффициенты конверсии графиков
    conversion_transposed = conversion.T
    for column in conversion_transposed.columns:
        fig.add_trace(
            go.Scatter(x=conversion_transposed.index, y=conversion_transposed[column],
                       mode='lines', name=str(column)),row=1, col=1)

    # Подготовка и отображение динамики истории конверсий
    columns = [name for name in conversion_history.index.names if name not in ['dt']]
    filtered_data = conversion_history.reset_index().pivot_table(
        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'
    )
    filtered_data = filter_data(filtered_data, window)
    for column in filtered_data.columns:
        fig.add_trace(
            go.Scatter(x=filtered_data.index, y=filtered_data[column], mode='lines',
                       name=str(column)), row=1, col=2)

    fig.update_xaxes(title_text='Лайфтайм', row=1, col=1)
    fig.update_xaxes(title_text='Дата привлечения', row=1, col=2)

    fig.update_layout(title='Конверсия', height=600, width=1200, showlegend=False)
    fig.update_layout(legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01))
    fig.show()

# Cкользящее среднее, поможет сгладить резкие колебания и выявить общую тенденцию

def filter_data(df, window):
    for column in df.columns.values:
        df[column] = df[column].rolling(window).mean()
    return df

# Удержание с разбивкой по каналу:

dimensions = ['utm_source']
retention_raw, retention_grouped, retention_history = get_retention(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_retention(retention_grouped, retention_history, horizon_days)

"""Благотворительный фонд сотрудничает с многочисленными площадками, которые предоставляют возможность размещения рекламы. Это включает в себя рекламные кампании в мессенджерах, социальных сетях и др. различных интернет-площадках, а также рекламу по мобильным операторам.

Яндекс.Директ демонстрирует более высокую стабильность удержания благодаря своей роли в бизнес-процессах и постоянной необходимости в использовании платформы для оптимизации рекламных кампаний.

Яндекс.Дзен менее стабилен в удержании пользователей, что может быть связано с особенностями потребления контента и изменяющимися интересами пользователей.
"""

# Конверсия с разбивкой по каналу:

conversion_raw, conversion_grouped, conversion_history = get_conversion(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_conversion(conversion_grouped, conversion_history, horizon_days)

"""С социальных сетей пользователи конвертируются лучше. С внедрением новшеств конверсия возросла в 2 раза."""

source_counts = retention_raw.reset_index().groupby('sex')['utm_source'].value_counts()
source_counts_normalized = retention_raw.reset_index().groupby('sex')['utm_source'].value_counts(normalize=True)

source_counts = source_counts.to_frame('активность')
source_counts_normalized = source_counts_normalized.to_frame('доля')

result = pd.concat([source_counts, source_counts_normalized], axis=1)
print(result.head())

"""Пользователи, перешедшие с Маркетлог и ВК, проявляют большую активность и лучше удерживаются."""

# Удержание с разбивкой по подписке:

dimensions = ['subscriptionsdobroaifissubscribed']
retention_raw, retention_grouped, retention_history = get_retention(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_retention(retention_grouped, retention_history, horizon_days)

fig = px.histogram(profiles,
                   x='subscriptionsdobroaifissubscribed',
                   color='areaname',
                   range_x=[0, 2],
                   title='Распределение подписок по городам',
                   nbins=10,
                   barmode='overlay')
fig.update_xaxes(title_text='Значение')
fig.update_yaxes(title_text='Частота')
fig.update_layout(
    legend=dict(
    title='Город'))
fig.show()

"""В данных преобладают пользователи с подпиской."""

# Конверсия с разбивкой по подписке:

conversion_raw, conversion_grouped, conversion_history = get_conversion(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_conversion(conversion_grouped, conversion_history, horizon_days)

"""С апреля 2023 года заметно увеличилась конверсия пользователей, не оформивших подписку."""

# Конверсия с разбивкой по гендеру:

dimensions = ['sex']
conversion_raw, conversion_grouped, conversion_history = get_conversion(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_conversion(conversion_grouped, conversion_history, horizon_days)

"""С января 2023 года наблюдается значительное увеличение числа пользователей мужского пола и пользователей, пол которых не указан."""

# Удержание с разбивкой по городу:

dimensions = ['areaname']
retention_raw, retention_grouped, retention_history = get_retention(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_retention(retention_grouped, retention_history, horizon_days)

lifetime = retention_raw[retention_raw['lifetime'] > 0].groupby(
    'areaname', as_index=False)['lifetime'].agg(
        'max').sort_values(by='lifetime', ascending=False)
lifetime

"""Вена, Екатеринбург, Москва, Уфа и Новороссийск являются городами-лидерами по удержанию клиентов."""

# Конверсия с разбивкой по городу:

conversion_raw, conversion_grouped, conversion_history = get_conversion(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_conversion(conversion_grouped, conversion_history, horizon_days)

"""Присутствие штаб-квартиры ООН в Вене играет важную роль в стабильном удержании и конверсии пользователей, предоставляя благотворительному фонду множество возможностей для взаимодействия и привлечения новых сторонников. Используя ресурсы и возможности, предоставляемые ООН, фонд может эффективно укрепить свои позиции и расширить поддержку своих инициатив."""

fig = px.histogram(id_donor_order,
                   x='totalprice',
                   color='areaname',
                   range_x=[0, 13000],
                   title='Распределение взносов по городам',
                   nbins=1000,
                   barmode='overlay')
fig.update_xaxes(title_text='Значение')
fig.update_yaxes(title_text='Частота')
fig.update_layout(
    legend=dict(
    title='Город'))
fig.show()

minimum_receipt = id_donor_order.groupby('areaname')['totalprice'].min().reset_index()
minimum_receipt.sort_values(by='totalprice', ascending=False)

"""Большие суммы чеков могут свидетельствовать о более высоком уровне экономического благополучия города. Кроме того, в некоторых странах существуют налоговые льготы для благотворительных взносов, что побуждает людей делать более значительные пожертвования. Это также может указывать на высокую мотивацию и осознанность доноров в отношении благотворительности."""

max_price = id_donor_order.groupby('areaname', as_index=False)['totalprice'].agg('sum').sort_values(by='totalprice', ascending=False)
max_price

"""Большинство взносов поступает из крупных городов и столиц."""

# Смотрим удержание с разбивкой по активности:

dimensions = ['user_action']
retention_raw, retention_grouped, retention_history = get_retention(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_retention(retention_grouped, retention_history, horizon_days)

"""Пользователям требуется несколько дней, чтобы ознакомиться с содержанием рассылки, оценить фонд и принять решение о взаимодействии."""

day_price = order.groupby('day_of_week', as_index=False)['totalprice'].agg('sum').sort_values(by='totalprice', ascending=False)
day_price

"""Предпочтительные дни для внесения взносов — вторник, четверг и пятница. Скорее всего, пожертвования в фонд делаются в свободное время как второстепенная задача."""

# Смотрим конверсию с разбивкой по активности:

conversion_raw, conversion_grouped, conversion_history = get_conversion(
    profiles, id_donor, order, channels, observation_date, horizon_days, dimensions=dimensions)

plot_conversion(conversion_grouped, conversion_history, horizon_days)

"""Фонд динамично развивается, и к 2024 году видим рост числа пользователей, которые просматривают отчётность.

### Cтатистическая значимость различий между группами в плане наступления событий

Анализ поведения и характеристик пользователей, сгруппированных по гендерной принадлежности, позволяет сделать несколько важных выводов о паттернах взаимодействия с платформой.

Напишем функцию, которая перебирает все уникальные события в кадре данных и применяет функцию test_proportions_difference к каждому событию.
Нулевая гипотиза: статистически значимых различий между группами нет;
Альтернативная: существует статистически значимая разница в доле пользователей, совершивших покупку, между мужчинами и женщинами.
"""

'''Z-оценка: показывает, насколько сильно различаются пропорции двух групп относительно стандартного отклонения.
p-значение: вероятность наблюдения таких или более экстремальных значений Z-оценки, если нулевая гипотеза верна.
Если p-значение меньше заданного уровня значимости 0.05, нулевая гипотеза отвергается в пользу альтернативной гипотезы.'''

def test_proportions_difference(df, event):

    # Подсчет числа пользователей, совершивших событие в каждой группе
    user_counts = df[df['user_action'] == event].groupby('sex')['user_id'].nunique()

    # Подсчет общего числа пользователей в каждой группе
    total_users = df.groupby('sex')['user_id'].nunique()

    # Проверка статистической достоверности различий между группами
    for i in range(len(user_counts) - 1):
        for j in range(i + 1, len(user_counts)):
            z_score, p_value = proportions_ztest([user_counts[user_counts.index[i]], user_counts[user_counts.index[j]]], [total_users[total_users.index[i]], total_users[total_users.index[j]]])
            print(f'Событие {event}, группы {user_counts.index[i]} и {user_counts.index[j]}: Z-оценка = {z_score}, p-значение = {p_value}')

for event in profiles['user_action'].unique():
    test_proportions_difference(profiles, event)

"""### Анализ пользователей

Пользователи, не указавшие свой пол, демонстрируют определенные паттерны поведения:

1.  **Недействительные адреса электронной почты**:
    
    *   Эти пользователи чаще имеют недействительные адреса, что может свидетельствовать о попытке сохранить анонимность или защитить свою приватность.
2.  **Изменение данных и часового пояса**:
    
    *   Частые изменения данных и часового пояса также могут указывать на желание сохранить анонимность или избежать идентификации.
3.  **Отказ от подписки на рассылку**:
    
    *   Несмотря на отказ от подписки, такие пользователи делают больше взносов, что подтверждает их значимую финансовую активность, возможно, мотивированную желанием помочь без раскрытия личности.


### Гендерные различия в подписке на новости

1.  **Равенство в подписках**:
    
    *   Мужчины и женщины подписываются на новости в примерно равных количествах. Однако из-за большего числа женщин им отправляется меньше писем, что может указывать на более таргетированную рассылку для мужчин.
2.  **Фокус на пользователях**:
    
    *   Рассылка, вероятно, ориентирована на менее активных пользователей с целью повышения вовлеченности.

### Пожертвования и гендерные различия

1.  **Отсутствие различий в пожертвованиях**:
    
    *   Взнос в размере 1500 рублей присутствует во всех группах, а пожертвования в 1000 рублей не отличаются между мужчинами и женщинами.
2.  **Высокие взносы анонимных пользователей**:
    
    *   Анонимные пользователи вносят суммы, превышающие 1000 рублей, что подтверждает их значительный вклад.

### Специфическое поведение волонтеров и пользователей

1.  **Тайные пожертвования мужчин**:
    
    *   В марте 2023 года новости для разовых пожертвований не различались между пользователями с неуказанным полом и мужчинами, что позволяет предположить, что анонимные пользователи — это, возможно, мужчины-волонтеры.


### Рекуррентные пожертвования и сезонные тренды

1.  **Майские рекуррентные пожертвования**:
    
    *   В мае рекуррентные пользователи с неуказанным полом, возможно, являются женщинами, что требует дополнительного анализа.
2.  **Февральские возвраты подписок**:
    
    *   В феврале возврат подписок не имел статистически значимых различий, что может указывать на общие проблемы с подписками.
3.  **Активность перед праздниками**:
    
    *   Пользователи проявляют повышенный интерес к новостям перед новогодними праздниками.

### Дополнительные наблюдения

1.  **Учителя и агитация**:
    
    *   Событие ко Дню учителя может свидетельствовать о взаимообмене, где школы проводят агитацию за сборы, а реклама направлена на родителей через учителей.
2.  **Иностранные сборы**:
    
    *   Проводятся иностранные сборы, что предполагает наличие филиалов в других странах.
3.  **Ошибки в именах**:
    
    *   Ошибки в именах (например, Савелий и Савелия с одной фамилией) указывают на необходимость улучшения качества данных.
"""

churn_rates = []  # Список для хранения процентов оттока по месяцам

# Определение временного интервала анализа
start_date = pd.to_datetime('2021-01-01')
end_date = pd.to_datetime('2024-05-01')

# Цикл по месяцам
while start_date < end_date:
    # Определение начальной и конечной даты для текущего месяца
    period_start = start_date
    period_end = start_date + pd.offsets.MonthEnd(1)

    # Фильтрация данных за текущий месяц
    orders_in_period = order[(order['firstactiondatetimeutc'] >= period_start) & (order['firstactiondatetimeutc'] <= period_end)]

    # Определение клиентов, покинувших бизнес за текущий месяц
    churned_customers = orders_in_period['user_id'].unique()

    # Определение общего количества клиентов на начало текущего месяца
    if start_date.month == 1:  # Если начало года, то начальное количество клиентов равно общему количеству клиентов
        start_period_customers = order[order['firstactiondatetimeutc'] < period_start]['user_id'].unique()
    else:  # Иначе общее количество клиентов на начало месяца равно количеству клиентов на начало предыдущего месяца
        prev_period_start = start_date - pd.offsets.MonthEnd(1)
        start_period_customers = order[(order['firstactiondatetimeutc'] >= prev_period_start) & (order['firstactiondatetimeutc'] < period_start)]['user_id'].unique()

    # Процент оттока для текущего месяца
    if len(start_period_customers) > 0:
        churn_rate = (len(churned_customers) / len(start_period_customers)) * 100
    else:
        churn_rate = 0  # Если начальное количество клиентов равно нулю, то процент оттока также равен нулю

    # Добавить процент оттока в список
    churn_rates.append((start_date.strftime('%Y-%m'), churn_rate))

    # Перейти к следующему месяцу
    start_date = start_date + pd.offsets.MonthBegin(1)

print("Процент оттока по месяцам:")
for month, churn_rate in churn_rates:
    print(f"{month}: {churn_rate}%")

"""В начале каждого года наблюдаются низкие проценты оттока. Это может свидетельствовать о сезонных факторах, таких как:
- Время после новогодних праздников, когда пользователи возвращаются к повседневным делам и начинают активнее использовать приложение.
- В начале учебного года могут проводиться маркетинговые акции, стимулирующие удержание пользователей.

В некоторые месяцы отток равен нулю, что может быть связано с временными факторами, такими как:
- Успешные маркетинговые кампании.
- Отсутствие значимых изменений.

"""

# Определение периода анализа
end_date = pd.to_datetime('2024-05-01')
start_date = end_date - pd.DateOffset(months=6)

# Фильтрация заказов за выбранный период
orders_period = order[(order['firstactiondatetimeutc'] >= start_date) & (order['firstactiondatetimeutc'] < end_date)]

# Определение клиентов, покинувших бизнес (клиенты, у которых отсутствуют заказы за последний месяц)
churned_customers = orders_period['user_id'].unique()

# Определение общего количества клиентов на начало периода
start_period_customers = order[order['firstactiondatetimeutc'] < start_date]['user_id'].unique()

# Расчет процент оттока
churn_rate = (len(churned_customers) / len(start_period_customers)) * 100
print("Процент оттока клиентов за последние месяца:", churn_rate)

"""### Заключение

Анализ показал, что пользователи, действующие инкогнито, имеют специфическое поведение, направленное на сохранение анонимности, но при этом они вносят значительные финансовые вклады. Мужчины и женщины подписываются на новости в равной степени, но различия в рассылке могут быть связаны с таргетированием менее активных пользователей. Пожертвования и активности пользователей варьируются в зависимости от их статуса и периода, что указывает на необходимость более детализированного анализа и персонализации взаимодействия с разными группами пользователей.

Колебания оттока пользователей могут быть обусловлены внешними макроэкономическими факторами, такими как пандемии, политические события или изменения в законодательстве.

### Рекомендаций

1. **Прозрачность финансовой отчетности:** Повышение прозрачности может существенно повысить доверие как инвесторов, так и обычных пользователей. Расширьте доступ к детализированным отчетам о деятельности фонда, покажите, на что именно были потрачены средства и какой эффект был достигнут.

2. **Обратная связь:** Создайте удобный и понятный механизм для обратной связи. Это могут быть онлайн-опросы, обсуждения в социальных сетях или специальные форумы на сайте фонда. Это поможет не только укрепить доверие, но и лучше понять нужды и ожидания ваших доноров.

3. **Информационные кампании:** В неблагоприятных условиях важно показать, что ваш фонд продолжает эффективно работать и оказывать помощь. Помимо регулярных кампаний по информированию о своих проектах и достижениях, можно дополнительно внедрить публикации интервью с получателями помощи.

4. **Взаимодействие с крупными компаниями:** Продолжайте развивать партнерства с крупными корпорациями, подчеркивая обоюдную выгоду такого сотрудничества. Выгоднее демонстрировать не только благотворительность, но и социальную ответственность бизнеса.

5. **Использование современных технологий:** Разработайте мобильное приложение или улучшите существующий сайт для удобства пользователей и доноров. Это также может включать онлайн- платежи, удобные личные кабинеты и автоматическое обновление информации об использовании средств.

6. **Мониторинг и оценка:** Регулярно проводите мониторинг и оценку ваших программ и проектов, демонстрируя инвесторам четкие результаты и влияние на общество. Это повысит уверенность доноров в том, что их средства используются эффективно.

Следуя этим рекомендациям, фонд сможет укрепить свою репутацию и продолжить эффективное функционирование даже в условиях нестабильности.
"""